{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16277,"status":"ok","timestamp":1685808295775,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"kNeU2aRYlWCv","outputId":"de09f388-a64a-466f-9504-657333f509b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.29.2\n"]}],"source":["  !pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["1c048ef3a65046da80a1655ed32272b4","1a0c35b338584fd19869a930cbb1a486","51da5f88adc241cf9f12ccc2bb51c707","254571bb21114c02895796b2826d2a22","672880a844814377a0b83b42d56399be","f082a7979a81445586fb4625016f3a41","97f7b247001a45f1bcff6e2908f24c35","07a6bfff6af3412a8d6fe1d8dfdf672a","2a52bc93878f4b0db0cd85bcbe5750ed","1bda621ba3fd4b679c17e3bde18b1f60","93466cf4177842d3b3bca187ed78dce5","dc1e3087ab5c492fac7ee57384aa5e46","2d3726eb2c2e406d927b14a99fe44736","10d64ab110a540b38722393fec5b0038","acf763932834429986df933ba335e8bb","23aeb84935f24810a934c48eae79fb5e","299b8c98b11249b3890291609183c89c","0e87be67fc7648f2ba68d4a249778338","ffdbd4202f1246c19ef73cc4fa224b92","d52cb7d9962f4d4b92024298eafd8691","e4fe337cb748427d97587993b3c38b87","de2cccba15924568bcd4c05bde291645","8037a83af49e43869ae98096eb819c49","2d4bf2930d56458ba54b40955fed2e62","beb1efca3faf4d19a8173837d0e71544","662d1f32106a44fe88d718c3e14e353e","30c3e55d04aa4dc99083578b8e767f1b","0ae2103dce6f41b19c6442e77f79115b","c5dad91c35e84186be79478547d278b5","48af9e35816b475c9558f6aabebd35e4","5e177f8f97574b7d949fa012d0d2c46a","e8327d9b8ba340969256e4903b187bcd","071910cadc0c4c89ba2f14d59b06a50d","846b35e2d357446dba79486b4fa07108","a2d5bea0112340f195e7edb2ad0268ab","ed83558342334ef593bf023849719488","d1bce8be9e3a40a0a000e1fa9642da63","920ead3f8fbe42a7804e00358335ace0","ec6d4aef11754d7482454fbb2370751f","e12b51ee26bf437a809543b370228a99","764b1c1fed5e476fa1a3f8204b545b34","5e042b24933c4708a5beecbbf7ef04a3","f5043212c2d445ad8e5cc00c410694ce","09fe98ad83ae4811a7725699457e9d30"]},"executionInfo":{"elapsed":12055,"status":"ok","timestamp":1685793968647,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"oKONCK7UldVp","outputId":"1ca81604-09b7-46cf-8c6a-76336e42ddfc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c048ef3a65046da80a1655ed32272b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc1e3087ab5c492fac7ee57384aa5e46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8037a83af49e43869ae98096eb819c49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"846b35e2d357446dba79486b4fa07108"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModel\n","from transformers import BertConfig, BertTokenizer\n","from transformers import BertModel\n","\n","# Load pre-trained BERT model and tokenizer\n","model_name = \"bert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","bert_model = BertModel.from_pretrained(model_name, output_hidden_states = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1683819336640,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"ynxQoMeCPnie","outputId":"054d000e-0d91-4685-c32b-5a3c66e2bde8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["bert_model.device.type"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qnwZkpbl4-k"},"outputs":[],"source":["# Define input sentences\n","input_sentences = [\"This is the first sentence.\", \"This is the second sentence.\", \"This is the third sentence.\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683819561893,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"npylBc9-zmmN","outputId":"40644ba7-7f17-4ddc-d033-4473c78d07fa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[    2, 32071,  9574,  6262, 28653, 64287, 15534,  1012,     4],\n","        [    2, 32071,  9574,  6262, 50431, 64287, 15534,  1012,     4],\n","        [    2, 32071,  9574,  6262, 66741, 64287, 15534,  1012,     4]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":12}],"source":["model_inputs = tokenizer(input_sentences, return_tensors=\"pt\", padding=True, truncation=True)\n","model_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_iaQEGWbtgx-"},"outputs":[],"source":["# Feed inputs through BERT model and get final hidden states of last layer\n","outputs = bert_model(input_ids=model_inputs.input_ids, attention_mask=model_inputs.attention_mask)\n","final_hidden_states = outputs.last_hidden_state"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1683228946660,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"XcCWpUaU47CV","outputId":"b86faaf8-9aaf-4a98-de39-fe8849f0c15b"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","2\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","3\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","4\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","5\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","6\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","7\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","8\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","9\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","10\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","11\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","12\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n","13\n","torch.Size([3, 8, 768])\n","--------------------------------------------------\n"]}],"source":["for i, layer in enumerate(outputs[2]):\n","  print(i + 1)\n","  print(layer.shape)\n","  print(\"-\" * 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cYOydcP2VX5"},"outputs":[],"source":["# 3, 8, 768 --> output[0].shape\n","# 3, 768    --> output[1].shape\n","# ...       --> output[2].shape shown above (consists of all 13 layers)\n","# 3, 8, 768 --> final_hidden_state (batch_size, tokens, hidden_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683228946661,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"P0fnaTXetVHv","outputId":"b334d153-4ac8-432f-ee23-bc35862e0d2b"},"outputs":[{"data":{"text/plain":["torch.Size([3, 8, 768])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["final_hidden_states.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1683228946662,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"zdT3qWpGXPNg","outputId":"22b2a76c-a31e-4889-863f-2b0a298377de"},"outputs":[{"data":{"text/plain":["torch.Size([3, 8])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model_inputs.attention_mask.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1683228946662,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"3TwEFF4OXgQX","outputId":"c33866d6-fe00-4466-b31d-b9870946dffd"},"outputs":[{"data":{"text/plain":["tensor([[8],\n","        [8],\n","        [8]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["torch.sum(model_inputs.attention_mask, dim=1, keepdim=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1683228946663,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"_Y10ss4k1FNQ","outputId":"af220365-de3e-4832-8266-f1e0257f241f"},"outputs":[{"data":{"text/plain":["torch.Size([1, 3, 768])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["averaged_embeddings = torch.sum(final_hidden_states, dim=1) / torch.sum(model_inputs.attention_mask, dim=1, keepdim=True)\n","averaged_embeddings = averaged_embeddings.unsqueeze(0)\n","averaged_embeddings.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2750,"status":"ok","timestamp":1683228949402,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"HERsP1BHYNCy","outputId":"55bf52e4-a234-40a3-899c-a524d6ef6872"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["second_bert_model = BertModel.from_pretrained(model_name, output_hidden_states = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahwEP4IFi0jk"},"outputs":[],"source":["my_inputs = torch.cat((averaged_embeddings[0] , torch.randn(600, 768))).unsqueeze(0)\n","\n","# this is example of having more than 512 tokens for BERT input and results in error"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683228949403,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"Haypr6mEYI64","outputId":"6d398c75-1755-4fbd-d936-7200237f4a3a"},"outputs":[{"data":{"text/plain":["torch.Size([1, 3, 768])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["second_bert_output = second_bert_model(inputs_embeds=averaged_embeddings)\n","\n","# Access the output embeddings or other outputs from the second BERT model\n","last_embeddings = second_bert_output.last_hidden_state\n","last_embeddings.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":944,"status":"ok","timestamp":1683191615579,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"LK1JrxppCZdb","outputId":"3904fd90-735f-4d68-d6c9-b957d622e285"},"outputs":[{"data":{"text/plain":["tensor([[[ 0.0442,  0.5528, -0.0934,  ...,  0.0542, -0.1767,  0.2576],\n","         [ 0.0613,  0.5681, -0.0807,  ...,  0.0670, -0.1715,  0.2448],\n","         [ 0.0544,  0.5678, -0.0696,  ...,  0.0680, -0.1653,  0.2496]]],\n","       grad_fn=<NativeLayerNormBackward0>)"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["last_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2148,"status":"ok","timestamp":1683198811644,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"mvwyHBW2CAFT","outputId":"400de73c-944e-40b4-8dde-860f676143ea"},"outputs":[{"data":{"text/plain":["tensor([[[ 0.0442,  0.5528, -0.0934,  ...,  0.0542, -0.1767,  0.2576],\n","         [ 0.0613,  0.5681, -0.0807,  ...,  0.0670, -0.1715,  0.2448],\n","         [ 0.0544,  0.5678, -0.0696,  ...,  0.0680, -0.1653,  0.2496]]],\n","       grad_fn=<NativeLayerNormBackward0>)"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["# below code shows we don't need to provide attnetion mask to the second bert\n","my_attention_mask = torch.ones(1, 3)\n","# my_attention_mask[0,0] = 0\n","mmd = second_bert_model(inputs_embeds=averaged_embeddings, attention_mask=my_attention_mask)\n","mmd.last_hidden_state"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":789,"status":"ok","timestamp":1685793010741,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"6za_LTv9f2aS","outputId":"cf83e9bd-1ec8-49e8-90f3-f09df364c292"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 4])"]},"metadata":{},"execution_count":6}],"source":["torch.ones(2,3,4).mean(axis=1).shape"]},{"cell_type":"code","source":["tokenizer(users_tweets[0], truncation=True, padding=True, return_tensors=\"pt\")"],"metadata":{"id":"Ko7xoLOeeRlP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.batch_encode_plus(users_tweets, truncation=True,\n","    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","    return_token_type_ids=True,\n","    return_attention_mask=True,\n","    padding='max_length',\n","    return_tensors='pt')"],"metadata":{"id":"T7n1Q6x-dINR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.kill(os.getpid(), 9)"],"metadata":{"id":"FQ2vDh66J9G3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"aDB0vw3RLpyC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688975376704,"user_tz":-210,"elapsed":19888,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}},"outputId":"d5ebe13f-ec40-491a-cf5c-660bf6523055"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QK7e5laclwFn","executionInfo":{"status":"ok","timestamp":1688975400509,"user_tz":-210,"elapsed":21070,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}},"outputId":"f1e98e2f-8e55-443c-8b7a-035041e0d017"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import random\n","top_k = 700\n","def make_trait(row):\n","    row[\"trait_0\"] = 0.0 if row[\"mbti_result\"][0] == \"I\" else 1.0\n","    row[\"trait_1\"] = 0.0 if row[\"mbti_result\"][1] == \"N\" else 1.0\n","    row[\"trait_2\"] = 0.0 if row[\"mbti_result\"][2] == \"T\" else 1.0\n","    row[\"trait_3\"] = 0.0 if row[\"mbti_result\"][3] == \"J\" else 1.0\n","    tweets = row[\"tweets\"]\n","    tweets_length = len(tweets)\n","    if tweets_length > top_k:\n","      row[\"tweets\"] = random.sample(tweets, top_k)\n","    return row"],"metadata":{"id":"4UZ4TKDCoUaa","executionInfo":{"status":"ok","timestamp":1688978339011,"user_tz":-210,"elapsed":3,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"X-toOkmtoaM7","executionInfo":{"status":"ok","timestamp":1688978342074,"user_tz":-210,"elapsed":375,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["df = pd.read_json(\"/content/drive/MyDrive/NLP/Project/datasets.json\")"],"metadata":{"id":"OprDMR-VoWco","executionInfo":{"status":"ok","timestamp":1688978359819,"user_tz":-210,"elapsed":17398,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["df = df.apply(make_trait, axis=1)\n","df = df.iloc[:400]"],"metadata":{"id":"3jnEKb5trqQD","executionInfo":{"status":"ok","timestamp":1688978369859,"user_tz":-210,"elapsed":10052,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","SEED_NUM = 1234\n","labels = df[\"trait_2\"]\n","\n","X_train, X_test, y_train, y_test = train_test_split(df[\"tweets\"], labels, test_size=0.2,\n","                                                                    random_state=SEED_NUM)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25,\n","                                                                  random_state=SEED_NUM)\n","X_train = X_train.tolist()\n","X_test = X_test.tolist()\n","X_val = X_val.tolist()\n","y_train = y_train.tolist()\n","y_test = y_test.tolist()\n","y_val = y_val.tolist()"],"metadata":{"id":"ge_BfGnkr_kr","executionInfo":{"status":"ok","timestamp":1688978588310,"user_tz":-210,"elapsed":335,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":25,"metadata":{"id":"VY-tYZtRmmji","executionInfo":{"status":"ok","timestamp":1688978370340,"user_tz":-210,"elapsed":4,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"outputs":[],"source":["import torch\n","import math\n","from transformers import AutoTokenizer, AutoModel\n","from transformers import BertConfig, BertTokenizer\n","from transformers import BertModel\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import gc\n","from transformers import set_seed\n","\n","SEED_NUM = 1234\n","MAX_TOKENS = 512\n","DROPOUT_PROB = 0.1\n","HIDDEN_SIZE = 768\n","NUM_LABELS = 2\n","LAST_NUM_NEURON = 1\n","NUM_EPOCHS = 2\n","BATCH_SIZE = 32\n","torch.manual_seed(SEED_NUM)\n","set_seed(SEED_NUM)\n","# torch.backends.cudnn.deterministic = True\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","class BatchTokenizerDataset(Dataset):\n","    def __init__(self, input_ids, attention_mask):\n","        self.input_ids = input_ids\n","        self.attention_mask = attention_mask\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return (self.input_ids[idx], self.attention_mask[idx])\n","\n","class TweetsPersonality(nn.Module):\n","\n","\n","    def __init__(self, model_name):\n","        super(TweetsPersonality, self).__init__()\n","\n","\n","        self.tweets_bert = BertModel.from_pretrained(model_name)  # first BERT model which is feature extractor of a single user tweets\n","\n","        for param in self.tweets_bert.parameters():\n","            param.requires_grad = False\n","\n","        self.embedding_bert = BertModel.from_pretrained(model_name)  # second BERT model which takes as input embedding of batch of tweets\n","\n","        # for param in self.embedding_bert.parameters():\n","        #     param.requires_grad = False\n","\n","        # self.accumulate_bert = BertModel.from_pretrained(model_name)  # third BERT model which takes as input embeddings of each batch\n","\n","        self.dropout = nn.Dropout(DROPOUT_PROB)  # dropout layer\n","\n","        self.classifier = nn.Linear(HIDDEN_SIZE, LAST_NUM_NEURON)  # linear binary classifier layer\n","\n","    def handle_limit_tokens_size(self, embeds):\n","        tweets_len = embeds.shape[0]\n","        if tweets_len > MAX_TOKENS:\n","            merge_num = math.ceil(tweets_len / MAX_TOKENS)  # each merge_num tweets are averaged together\n","            # for example if it's 4, every 4 tweets are average embeds[:4], embeds[4:8], ...\n","\n","\n","            reshaped_main_tweets = embeds[:merge_num * (tweets_len // merge_num)].view((tweets_len // merge_num), merge_num, -1).mean(axis=1)\n","            # for example if MAX_TOKEN = 500 and we have 1602 tweets --> merge_num = 4, (tweets_len // merge_num) = 400 , merge_num * (tweets_len // merge_num) = 1600\n","            # reshaped to (tweets_len // merge_num, merge_num, 768) and the            # get mean which results in (tweets_len // merge_num, 768)\n","\n","            remainder_tweets = embeds[merge_num * (tweets_len // merge_num) : tweets_len]\n","            # we are getting the two remainder from 1600 to 1602\n","\n","            if len(remainder_tweets) > 0:\n","                reshaped_remainder_tweets = remainder_tweets.mean(axis=0).unsqueeze(0)  # get mean which results in (1, 768)\n","                return torch.cat((reshaped_main_tweets, reshaped_remainder_tweets))\n","\n","            return reshaped_main_tweets\n","\n","\n","        return embeds\n","\n","\n","    def forward(self, input_ids, attention_mask):\n","        # add for here for batch_size of 32\n","\n","        batch_embeddings = []\n","        total_tweets_length = input_ids.shape[0]\n","        print(f\"batch_size : {BATCH_SIZE}, number of batch : {math.ceil(total_tweets_length / BATCH_SIZE)}\")\n","        tokenized_dataset = BatchTokenizerDataset(input_ids, attention_mask)\n","        data_loader = DataLoader(tokenized_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","\n","        counter = 0\n","        # print(\"in batch\", end=\" \")\n","        for input_ids_batch, attention_mask_batch in data_loader:\n","            extracted_embeddings = self.tweets_bert(input_ids=input_ids_batch, attention_mask=attention_mask_batch)  # applying first BERT\n","\n","            sentences_embedding = extracted_embeddings.last_hidden_state  # last layer of BERT(extract all tweets for a user embeddings)\n","\n","            CLS_embeddings = sentences_embedding[:, 0, :]  # extract CLS layer\n","            # (batch_size, tokens, hidden_size) reshaped to (batch_size, hidden_size)\n","\n","\n","            CLS_embeddings = CLS_embeddings.unsqueeze(0)  # add one outer dim for creating batch_size of length 1. (1, MAX_TOKENS, HIDDEN_SIZE)\n","\n","            last_embeddings = self.embedding_bert(inputs_embeds=CLS_embeddings)  # apply second BERT to extract final embeddings\n","\n","            CLS_embeddings = last_embeddings.last_hidden_state[:, 0, :]  # extract the CLS token of second BERT\n","\n","            batch_embeddings.append(CLS_embeddings)\n","            # batch_embeddings = torch.cat((batch_embeddings, CLS_embeddings.to(\"cpu\"))).to(\"cpu\")\n","            counter += 1\n","\n","            # print(f\"{counter} ->\", end=\" \")\n","            # print(f\"batch_embeddings shape : {batch_embeddings.shape}\")\n","\n","            # del extracted_embeddings\n","            # del sentences_embedding\n","            # del last_embeddings\n","            # del CLS_embeddings\n","            # gc.collect()\n","            # torch.cuda.empty_cache()\n","\n","        # print(\"\\nstarting to feed second BERT\")\n","        batch_embeddings = torch.cat(batch_embeddings)\n","\n","        batch_embeddings = self.handle_limit_tokens_size(batch_embeddings)\n","\n","        feed_input_second_bert = batch_embeddings.unsqueeze(0)\n","\n","        last_embeddings = self.embedding_bert(inputs_embeds=feed_input_second_bert)  # apply second BERT to extract final embeddings\n","\n","        CLS_embeddings = last_embeddings.last_hidden_state[:, 0, :]  # extract the CLS token of second BERT\n","\n","        pooled_output = self.dropout(CLS_embeddings)  # apply dropout layer\n","\n","        logits = self.classifier(pooled_output)  # apply linear layer\n","\n","        # del batch_embeddings, feed_input_second_bert, last_embeddings, CLS_embeddings, pooled_output\n","        # gc.collect()\n","        # torch.cuda.empty_cache()\n","\n","        return torch.sigmoid(logits.squeeze(-1))\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237,"referenced_widgets":["3accb3cd0e194ab3964d8e8e636aefdf","3245a40df6554f2990204beadb1aeed6","50c383cb01fb479684db96664fffc8d0","4ae690ee871c4e9f8ed6ab21cd4337bd","61e701f5504a4795af573f4cf30fbacf","29bc3717845d4a60b5c555020fa95b44","0497a4e9d6f84b59b3ec02c77776f0dd","ec003144413c4edc940c8a9f441575e5","6a71746f9a0040bcb9e4fe1f5b68ea8e","670f65a204dc4d8aab54d870a86c5252","41f5f1dc5ea941e6b8e788af94cfa10e","32dbe4191f3f4f7e8b8607b38f1c0eb9","9d64a0600b50494e8e4e6f32f8bcb994","befea868a39d43ca95a20880e661f030","ff2775a5270b435a8af558a27fafe083","48427f4248334ca1856d97bfb718b912","e72d5c408be44ab3b2ce04e604ee35d5","531f3676ec7a42848998ea0156c6dffc","29a8c5d1902944e99bda8e4b6f251ae5","b4827b397a214b4ab70afb77c2e98aa8","fb9a147d0d73458db14ede2f9693947a","0cf3db4fdadf4d498ea453577215eafa","37512743933c488e820b02a8a8c9d746","54990aba7e41459bbb2f2d4383f9a794","1b93cdcef2824a2ab03d9f640b339de0","86ebc3942dc8403d966dc02f5fd47914","24dfd707e49444468f191cdde5d7b8c0","df0f501fc31a426ab356fe06c11b67bd","9f30803ec2994e98881b3c1ffdedb663","276b5392fdee4085b6c9edcfbdff9243","d0f7c640074a468e9c1a37172abed3e0","8edcb5ce34844933968b6b67b1481d57","918dbb0d2d9b47f49dbadf2af07a5589"]},"executionInfo":{"elapsed":20989,"status":"ok","timestamp":1688975491027,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"eg82D3wfz_pd","outputId":"672f16ac-41db-469b-eec5-9a0f94cb5f1c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3accb3cd0e194ab3964d8e8e636aefdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/440 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32dbe4191f3f4f7e8b8607b38f1c0eb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37512743933c488e820b02a8a8c9d746"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# users_tweets = [[\"i'm so grateful for this occassion\", \"my name is Mohammad and this is what I don't like\", \"here there is some shity things\"] * 4000 + [\"wow awesome\"],\n","#          [\"wow this is gonna hurt\", \"can't imagine a situation better than this\"] * 300] * 2000\n","\n","torch.cuda.empty_cache()\n","tokenizer = BertTokenizer.from_pretrained('HooshvareLab/bert-fa-base-uncased', model_max_length=512)\n","\n","model = TweetsPersonality('HooshvareLab/bert-fa-base-uncased').to(device)\n","\n","loss_fn = nn.BCELoss()\n","\n","# Define the optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","\n","\n","label2id = {\"I\" : 0, \"E\" : 1}\n","id2label = {1 : \"E\", 0 : \"I\"}\n","\n","# labels = torch.tensor([0, 1] * 600).unsqueeze(1).to(device)"]},{"cell_type":"code","source":["# approches\n","# 1. set the require_grad = False for at least one model(when I use output of first model to feed second model I get gpu memory issue)\n","# 2. average on each batch output(can't be fine tuned)\n","# 3. merge each users tweets into a document and then make overlapping text(sliding window approach)\n","# 4. use bert as feature extractor\n","\n","# ---\n","# best approach is fine tune BERT on each subpart with at most 512 tokens but use their whole part label(for example if document is divided into 12 parts fine tune each\n","# 12 part separately but with their main label) and after that use this BERT as feature extractor and then feed this extracted features to another BERT\n","# and then you can fine tune it on second BERT\n","\n","# ---\n","# alternative without fine tuning is I just freeze first BERT and use it as feature extractor and feed embedding to the second BERT and fine tune on second BERT that's it."],"metadata":{"id":"diSgHb6CMwfS","executionInfo":{"status":"ok","timestamp":1688975491028,"user_tz":-210,"elapsed":37,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1431571,"status":"ok","timestamp":1688980042443,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"},"user_tz":-210},"id":"zxS-sCtbql83","outputId":"49b649b4-90c1-4e0a-bb69-a8ed26e9d088"},"outputs":[{"output_type":"stream","name":"stdout","text":["batch_size : 32, number of batch : 9\n","on user number 1\n","batch_size : 32, number of batch : 4\n","on user number 2\n","batch_size : 32, number of batch : 22\n","on user number 3\n","batch_size : 32, number of batch : 6\n","on user number 4\n","batch_size : 32, number of batch : 10\n","on user number 5\n","batch_size : 32, number of batch : 22\n","on user number 6\n","batch_size : 32, number of batch : 22\n","on user number 7\n","batch_size : 32, number of batch : 22\n","on user number 8\n","batch_size : 32, number of batch : 2\n","on user number 9\n","batch_size : 32, number of batch : 22\n","on user number 10\n","batch_size : 32, number of batch : 16\n","on user number 11\n","batch_size : 32, number of batch : 7\n","on user number 12\n","batch_size : 32, number of batch : 19\n","on user number 13\n","batch_size : 32, number of batch : 22\n","on user number 14\n","batch_size : 32, number of batch : 22\n","on user number 15\n","batch_size : 32, number of batch : 22\n","on user number 16\n","batch_size : 32, number of batch : 22\n","on user number 17\n","batch_size : 32, number of batch : 4\n","on user number 18\n","batch_size : 32, number of batch : 22\n","on user number 19\n","batch_size : 32, number of batch : 22\n","on user number 20\n","batch_size : 32, number of batch : 4\n","on user number 21\n","batch_size : 32, number of batch : 7\n","on user number 22\n","batch_size : 32, number of batch : 22\n","on user number 23\n","batch_size : 32, number of batch : 22\n","on user number 24\n","batch_size : 32, number of batch : 13\n","on user number 25\n","batch_size : 32, number of batch : 22\n","on user number 26\n","batch_size : 32, number of batch : 15\n","on user number 27\n","batch_size : 32, number of batch : 22\n","on user number 28\n","batch_size : 32, number of batch : 8\n","on user number 29\n","batch_size : 32, number of batch : 22\n","on user number 30\n","batch_size : 32, number of batch : 22\n","on user number 31\n","batch_size : 32, number of batch : 22\n","on user number 32\n","batch_size : 32, number of batch : 22\n","on user number 33\n","batch_size : 32, number of batch : 22\n","on user number 34\n","batch_size : 32, number of batch : 22\n","on user number 35\n","batch_size : 32, number of batch : 22\n","on user number 36\n","batch_size : 32, number of batch : 22\n","on user number 37\n","batch_size : 32, number of batch : 14\n","on user number 38\n","batch_size : 32, number of batch : 22\n","on user number 39\n","batch_size : 32, number of batch : 17\n","on user number 40\n","batch_size : 32, number of batch : 22\n","on user number 41\n","batch_size : 32, number of batch : 22\n","on user number 42\n","batch_size : 32, number of batch : 16\n","on user number 43\n","batch_size : 32, number of batch : 17\n","on user number 44\n","batch_size : 32, number of batch : 15\n","on user number 45\n","batch_size : 32, number of batch : 10\n","on user number 46\n","batch_size : 32, number of batch : 22\n","on user number 47\n","batch_size : 32, number of batch : 4\n","on user number 48\n","batch_size : 32, number of batch : 22\n","on user number 49\n","batch_size : 32, number of batch : 7\n","on user number 50\n","batch_size : 32, number of batch : 22\n","on user number 51\n","batch_size : 32, number of batch : 22\n","on user number 52\n","batch_size : 32, number of batch : 6\n","on user number 53\n","batch_size : 32, number of batch : 11\n","on user number 54\n","batch_size : 32, number of batch : 8\n","on user number 55\n","batch_size : 32, number of batch : 7\n","on user number 56\n","batch_size : 32, number of batch : 22\n","on user number 57\n","batch_size : 32, number of batch : 3\n","on user number 58\n","batch_size : 32, number of batch : 4\n","on user number 59\n","batch_size : 32, number of batch : 22\n","on user number 60\n","batch_size : 32, number of batch : 22\n","on user number 61\n","batch_size : 32, number of batch : 8\n","on user number 62\n","batch_size : 32, number of batch : 22\n","on user number 63\n","batch_size : 32, number of batch : 22\n","on user number 64\n","batch_size : 32, number of batch : 22\n","on user number 65\n","batch_size : 32, number of batch : 22\n","on user number 66\n","batch_size : 32, number of batch : 3\n","on user number 67\n","batch_size : 32, number of batch : 9\n","on user number 68\n","batch_size : 32, number of batch : 22\n","on user number 69\n","batch_size : 32, number of batch : 22\n","on user number 70\n","batch_size : 32, number of batch : 22\n","on user number 71\n","batch_size : 32, number of batch : 22\n","on user number 72\n","batch_size : 32, number of batch : 15\n","on user number 73\n","batch_size : 32, number of batch : 22\n","on user number 74\n","batch_size : 32, number of batch : 22\n","on user number 75\n","batch_size : 32, number of batch : 22\n","on user number 76\n","batch_size : 32, number of batch : 22\n","on user number 77\n","batch_size : 32, number of batch : 22\n","on user number 78\n","batch_size : 32, number of batch : 22\n","on user number 79\n","batch_size : 32, number of batch : 22\n","on user number 80\n","batch_size : 32, number of batch : 22\n","on user number 81\n","batch_size : 32, number of batch : 22\n","on user number 82\n","batch_size : 32, number of batch : 22\n","on user number 83\n","batch_size : 32, number of batch : 21\n","on user number 84\n","batch_size : 32, number of batch : 22\n","on user number 85\n","batch_size : 32, number of batch : 22\n","on user number 86\n","batch_size : 32, number of batch : 22\n","on user number 87\n","batch_size : 32, number of batch : 22\n","on user number 88\n","batch_size : 32, number of batch : 22\n","on user number 89\n","batch_size : 32, number of batch : 22\n","on user number 90\n","batch_size : 32, number of batch : 8\n","on user number 91\n","batch_size : 32, number of batch : 22\n","on user number 92\n","batch_size : 32, number of batch : 16\n","on user number 93\n","batch_size : 32, number of batch : 6\n","on user number 94\n","batch_size : 32, number of batch : 22\n","on user number 95\n","batch_size : 32, number of batch : 17\n","on user number 96\n","batch_size : 32, number of batch : 20\n","on user number 97\n","batch_size : 32, number of batch : 15\n","on user number 98\n","batch_size : 32, number of batch : 22\n","on user number 99\n","batch_size : 32, number of batch : 22\n","on user number 100\n","batch_size : 32, number of batch : 22\n","on user number 101\n","batch_size : 32, number of batch : 22\n","on user number 102\n","batch_size : 32, number of batch : 5\n","on user number 103\n","batch_size : 32, number of batch : 22\n","on user number 104\n","batch_size : 32, number of batch : 22\n","on user number 105\n","batch_size : 32, number of batch : 22\n","on user number 106\n","batch_size : 32, number of batch : 22\n","on user number 107\n","batch_size : 32, number of batch : 22\n","on user number 108\n","batch_size : 32, number of batch : 22\n","on user number 109\n","batch_size : 32, number of batch : 21\n","on user number 110\n","batch_size : 32, number of batch : 7\n","on user number 111\n","batch_size : 32, number of batch : 12\n","on user number 112\n","batch_size : 32, number of batch : 5\n","on user number 113\n","batch_size : 32, number of batch : 9\n","on user number 114\n","batch_size : 32, number of batch : 22\n","on user number 115\n","batch_size : 32, number of batch : 22\n","on user number 116\n","batch_size : 32, number of batch : 22\n","on user number 117\n","batch_size : 32, number of batch : 22\n","on user number 118\n","batch_size : 32, number of batch : 22\n","on user number 119\n","batch_size : 32, number of batch : 22\n","on user number 120\n","batch_size : 32, number of batch : 22\n","on user number 121\n","batch_size : 32, number of batch : 22\n","on user number 122\n","batch_size : 32, number of batch : 5\n","on user number 123\n","batch_size : 32, number of batch : 15\n","on user number 124\n","batch_size : 32, number of batch : 22\n","on user number 125\n","batch_size : 32, number of batch : 22\n","on user number 126\n","batch_size : 32, number of batch : 7\n","on user number 127\n","batch_size : 32, number of batch : 22\n","on user number 128\n","batch_size : 32, number of batch : 14\n","on user number 129\n","batch_size : 32, number of batch : 22\n","on user number 130\n","batch_size : 32, number of batch : 4\n","on user number 131\n","batch_size : 32, number of batch : 22\n","on user number 132\n","batch_size : 32, number of batch : 22\n","on user number 133\n","batch_size : 32, number of batch : 13\n","on user number 134\n","batch_size : 32, number of batch : 17\n","on user number 135\n","batch_size : 32, number of batch : 22\n","on user number 136\n","batch_size : 32, number of batch : 22\n","on user number 137\n","batch_size : 32, number of batch : 22\n","on user number 138\n","batch_size : 32, number of batch : 22\n","on user number 139\n","batch_size : 32, number of batch : 22\n","on user number 140\n","batch_size : 32, number of batch : 22\n","on user number 141\n","batch_size : 32, number of batch : 22\n","on user number 142\n","batch_size : 32, number of batch : 22\n","on user number 143\n","batch_size : 32, number of batch : 22\n","on user number 144\n","batch_size : 32, number of batch : 22\n","on user number 145\n","batch_size : 32, number of batch : 15\n","on user number 146\n","batch_size : 32, number of batch : 22\n","on user number 147\n","batch_size : 32, number of batch : 22\n","on user number 148\n","batch_size : 32, number of batch : 22\n","on user number 149\n","batch_size : 32, number of batch : 18\n","on user number 150\n","batch_size : 32, number of batch : 22\n","on user number 151\n","batch_size : 32, number of batch : 22\n","on user number 152\n","batch_size : 32, number of batch : 22\n","on user number 153\n","batch_size : 32, number of batch : 22\n","on user number 154\n","batch_size : 32, number of batch : 22\n","on user number 155\n","batch_size : 32, number of batch : 5\n","on user number 156\n","batch_size : 32, number of batch : 6\n","on user number 157\n","batch_size : 32, number of batch : 22\n","on user number 158\n","batch_size : 32, number of batch : 22\n","on user number 159\n","batch_size : 32, number of batch : 4\n","on user number 160\n","batch_size : 32, number of batch : 22\n","on user number 161\n","batch_size : 32, number of batch : 22\n","on user number 162\n","batch_size : 32, number of batch : 15\n","on user number 163\n","batch_size : 32, number of batch : 22\n","on user number 164\n","batch_size : 32, number of batch : 22\n","on user number 165\n","batch_size : 32, number of batch : 22\n","on user number 166\n","batch_size : 32, number of batch : 5\n","on user number 167\n","batch_size : 32, number of batch : 3\n","on user number 168\n","batch_size : 32, number of batch : 5\n","on user number 169\n","batch_size : 32, number of batch : 21\n","on user number 170\n","batch_size : 32, number of batch : 10\n","on user number 171\n","batch_size : 32, number of batch : 18\n","on user number 172\n","batch_size : 32, number of batch : 22\n","on user number 173\n","batch_size : 32, number of batch : 8\n","on user number 174\n","batch_size : 32, number of batch : 22\n","on user number 175\n","batch_size : 32, number of batch : 22\n","on user number 176\n","batch_size : 32, number of batch : 22\n","on user number 177\n","batch_size : 32, number of batch : 6\n","on user number 178\n","batch_size : 32, number of batch : 11\n","on user number 179\n","batch_size : 32, number of batch : 22\n","on user number 180\n","batch_size : 32, number of batch : 22\n","on user number 181\n","batch_size : 32, number of batch : 16\n","on user number 182\n","batch_size : 32, number of batch : 6\n","on user number 183\n","batch_size : 32, number of batch : 22\n","on user number 184\n","batch_size : 32, number of batch : 22\n","on user number 185\n","batch_size : 32, number of batch : 22\n","on user number 186\n","batch_size : 32, number of batch : 22\n","on user number 187\n","batch_size : 32, number of batch : 22\n","on user number 188\n","batch_size : 32, number of batch : 22\n","on user number 189\n","batch_size : 32, number of batch : 22\n","on user number 190\n","batch_size : 32, number of batch : 21\n","on user number 191\n","batch_size : 32, number of batch : 22\n","on user number 192\n","batch_size : 32, number of batch : 22\n","on user number 193\n","batch_size : 32, number of batch : 18\n","on user number 194\n","batch_size : 32, number of batch : 19\n","on user number 195\n","batch_size : 32, number of batch : 22\n","on user number 196\n","batch_size : 32, number of batch : 16\n","on user number 197\n","batch_size : 32, number of batch : 22\n","on user number 198\n","batch_size : 32, number of batch : 22\n","on user number 199\n","batch_size : 32, number of batch : 21\n","on user number 200\n","batch_size : 32, number of batch : 22\n","on user number 201\n","batch_size : 32, number of batch : 22\n","on user number 202\n","batch_size : 32, number of batch : 22\n","on user number 203\n","batch_size : 32, number of batch : 22\n","on user number 204\n","batch_size : 32, number of batch : 22\n","on user number 205\n","batch_size : 32, number of batch : 11\n","on user number 206\n","batch_size : 32, number of batch : 22\n","on user number 207\n","batch_size : 32, number of batch : 5\n","on user number 208\n","batch_size : 32, number of batch : 22\n","on user number 209\n","batch_size : 32, number of batch : 16\n","on user number 210\n","batch_size : 32, number of batch : 22\n","on user number 211\n","batch_size : 32, number of batch : 22\n","on user number 212\n","batch_size : 32, number of batch : 11\n","on user number 213\n","batch_size : 32, number of batch : 22\n","on user number 214\n","batch_size : 32, number of batch : 22\n","on user number 215\n","batch_size : 32, number of batch : 22\n","on user number 216\n","batch_size : 32, number of batch : 22\n","on user number 217\n","batch_size : 32, number of batch : 22\n","on user number 218\n","batch_size : 32, number of batch : 22\n","on user number 219\n","batch_size : 32, number of batch : 2\n","on user number 220\n","batch_size : 32, number of batch : 6\n","on user number 221\n","batch_size : 32, number of batch : 22\n","on user number 222\n","batch_size : 32, number of batch : 22\n","on user number 223\n","batch_size : 32, number of batch : 21\n","on user number 224\n","batch_size : 32, number of batch : 4\n","on user number 225\n","batch_size : 32, number of batch : 22\n","on user number 226\n","batch_size : 32, number of batch : 22\n","on user number 227\n","batch_size : 32, number of batch : 22\n","on user number 228\n","batch_size : 32, number of batch : 22\n","on user number 229\n","batch_size : 32, number of batch : 10\n","on user number 230\n","batch_size : 32, number of batch : 22\n","on user number 231\n","batch_size : 32, number of batch : 22\n","on user number 232\n","batch_size : 32, number of batch : 8\n","on user number 233\n","batch_size : 32, number of batch : 18\n","on user number 234\n","batch_size : 32, number of batch : 6\n","on user number 235\n","batch_size : 32, number of batch : 22\n","on user number 236\n","batch_size : 32, number of batch : 17\n","on user number 237\n","batch_size : 32, number of batch : 6\n","on user number 238\n","batch_size : 32, number of batch : 22\n","on user number 239\n","batch_size : 32, number of batch : 22\n","on user number 240\n","Epoch 1/2 - Loss: 172.92429012060165\n","batch_size : 32, number of batch : 22\n","on user number 1\n","batch_size : 32, number of batch : 22\n","on user number 2\n","batch_size : 32, number of batch : 17\n","on user number 3\n","batch_size : 32, number of batch : 22\n","on user number 4\n","batch_size : 32, number of batch : 8\n","on user number 5\n","batch_size : 32, number of batch : 22\n","on user number 6\n","batch_size : 32, number of batch : 15\n","on user number 7\n","batch_size : 32, number of batch : 22\n","on user number 8\n","batch_size : 32, number of batch : 10\n","on user number 9\n","batch_size : 32, number of batch : 10\n","on user number 10\n","batch_size : 32, number of batch : 22\n","on user number 11\n","batch_size : 32, number of batch : 22\n","on user number 12\n","batch_size : 32, number of batch : 15\n","on user number 13\n","batch_size : 32, number of batch : 22\n","on user number 14\n","batch_size : 32, number of batch : 5\n","on user number 15\n","batch_size : 32, number of batch : 22\n","on user number 16\n","batch_size : 32, number of batch : 14\n","on user number 17\n","batch_size : 32, number of batch : 22\n","on user number 18\n","batch_size : 32, number of batch : 22\n","on user number 19\n","batch_size : 32, number of batch : 22\n","on user number 20\n","batch_size : 32, number of batch : 22\n","on user number 21\n","batch_size : 32, number of batch : 22\n","on user number 22\n","batch_size : 32, number of batch : 7\n","on user number 23\n","batch_size : 32, number of batch : 22\n","on user number 24\n","batch_size : 32, number of batch : 15\n","on user number 25\n","batch_size : 32, number of batch : 15\n","on user number 26\n","batch_size : 32, number of batch : 18\n","on user number 27\n","batch_size : 32, number of batch : 22\n","on user number 28\n","batch_size : 32, number of batch : 22\n","on user number 29\n","batch_size : 32, number of batch : 22\n","on user number 30\n","batch_size : 32, number of batch : 22\n","on user number 31\n","batch_size : 32, number of batch : 22\n","on user number 32\n","batch_size : 32, number of batch : 22\n","on user number 33\n","batch_size : 32, number of batch : 22\n","on user number 34\n","batch_size : 32, number of batch : 22\n","on user number 35\n","batch_size : 32, number of batch : 4\n","on user number 36\n","batch_size : 32, number of batch : 22\n","on user number 37\n","batch_size : 32, number of batch : 22\n","on user number 38\n","batch_size : 32, number of batch : 22\n","on user number 39\n","batch_size : 32, number of batch : 21\n","on user number 40\n","batch_size : 32, number of batch : 22\n","on user number 41\n","batch_size : 32, number of batch : 22\n","on user number 42\n","batch_size : 32, number of batch : 5\n","on user number 43\n","batch_size : 32, number of batch : 22\n","on user number 44\n","batch_size : 32, number of batch : 22\n","on user number 45\n","batch_size : 32, number of batch : 11\n","on user number 46\n","batch_size : 32, number of batch : 22\n","on user number 47\n","batch_size : 32, number of batch : 22\n","on user number 48\n","batch_size : 32, number of batch : 13\n","on user number 49\n","batch_size : 32, number of batch : 2\n","on user number 50\n","batch_size : 32, number of batch : 15\n","on user number 51\n","batch_size : 32, number of batch : 8\n","on user number 52\n","batch_size : 32, number of batch : 9\n","on user number 53\n","batch_size : 32, number of batch : 16\n","on user number 54\n","batch_size : 32, number of batch : 22\n","on user number 55\n","batch_size : 32, number of batch : 7\n","on user number 56\n","batch_size : 32, number of batch : 22\n","on user number 57\n","batch_size : 32, number of batch : 22\n","on user number 58\n","batch_size : 32, number of batch : 22\n","on user number 59\n","batch_size : 32, number of batch : 22\n","on user number 60\n","batch_size : 32, number of batch : 22\n","on user number 61\n","batch_size : 32, number of batch : 16\n","on user number 62\n","batch_size : 32, number of batch : 4\n","on user number 63\n","batch_size : 32, number of batch : 4\n","on user number 64\n","batch_size : 32, number of batch : 5\n","on user number 65\n","batch_size : 32, number of batch : 22\n","on user number 66\n","batch_size : 32, number of batch : 22\n","on user number 67\n","batch_size : 32, number of batch : 13\n","on user number 68\n","batch_size : 32, number of batch : 22\n","on user number 69\n","batch_size : 32, number of batch : 6\n","on user number 70\n","batch_size : 32, number of batch : 22\n","on user number 71\n","batch_size : 32, number of batch : 22\n","on user number 72\n","batch_size : 32, number of batch : 22\n","on user number 73\n","batch_size : 32, number of batch : 22\n","on user number 74\n","batch_size : 32, number of batch : 22\n","on user number 75\n","batch_size : 32, number of batch : 18\n","on user number 76\n","batch_size : 32, number of batch : 22\n","on user number 77\n","batch_size : 32, number of batch : 6\n","on user number 78\n","batch_size : 32, number of batch : 5\n","on user number 79\n","batch_size : 32, number of batch : 22\n","on user number 80\n","batch_size : 32, number of batch : 6\n","on user number 81\n","batch_size : 32, number of batch : 22\n","on user number 82\n","batch_size : 32, number of batch : 22\n","on user number 83\n","batch_size : 32, number of batch : 22\n","on user number 84\n","batch_size : 32, number of batch : 22\n","on user number 85\n","batch_size : 32, number of batch : 22\n","on user number 86\n","batch_size : 32, number of batch : 22\n","on user number 87\n","batch_size : 32, number of batch : 11\n","on user number 88\n","batch_size : 32, number of batch : 22\n","on user number 89\n","batch_size : 32, number of batch : 22\n","on user number 90\n","batch_size : 32, number of batch : 22\n","on user number 91\n","batch_size : 32, number of batch : 17\n","on user number 92\n","batch_size : 32, number of batch : 21\n","on user number 93\n","batch_size : 32, number of batch : 22\n","on user number 94\n","batch_size : 32, number of batch : 11\n","on user number 95\n","batch_size : 32, number of batch : 6\n","on user number 96\n","batch_size : 32, number of batch : 22\n","on user number 97\n","batch_size : 32, number of batch : 8\n","on user number 98\n","batch_size : 32, number of batch : 15\n","on user number 99\n","batch_size : 32, number of batch : 22\n","on user number 100\n","batch_size : 32, number of batch : 22\n","on user number 101\n","batch_size : 32, number of batch : 22\n","on user number 102\n","batch_size : 32, number of batch : 22\n","on user number 103\n","batch_size : 32, number of batch : 22\n","on user number 104\n","batch_size : 32, number of batch : 22\n","on user number 105\n","batch_size : 32, number of batch : 22\n","on user number 106\n","batch_size : 32, number of batch : 22\n","on user number 107\n","batch_size : 32, number of batch : 17\n","on user number 108\n","batch_size : 32, number of batch : 22\n","on user number 109\n","batch_size : 32, number of batch : 14\n","on user number 110\n","batch_size : 32, number of batch : 4\n","on user number 111\n","batch_size : 32, number of batch : 16\n","on user number 112\n","batch_size : 32, number of batch : 4\n","on user number 113\n","batch_size : 32, number of batch : 22\n","on user number 114\n","batch_size : 32, number of batch : 10\n","on user number 115\n","batch_size : 32, number of batch : 22\n","on user number 116\n","batch_size : 32, number of batch : 22\n","on user number 117\n","batch_size : 32, number of batch : 22\n","on user number 118\n","batch_size : 32, number of batch : 22\n","on user number 119\n","batch_size : 32, number of batch : 22\n","on user number 120\n","batch_size : 32, number of batch : 22\n","on user number 121\n","batch_size : 32, number of batch : 6\n","on user number 122\n","batch_size : 32, number of batch : 22\n","on user number 123\n","batch_size : 32, number of batch : 22\n","on user number 124\n","batch_size : 32, number of batch : 18\n","on user number 125\n","batch_size : 32, number of batch : 22\n","on user number 126\n","batch_size : 32, number of batch : 6\n","on user number 127\n","batch_size : 32, number of batch : 6\n","on user number 128\n","batch_size : 32, number of batch : 21\n","on user number 129\n","batch_size : 32, number of batch : 22\n","on user number 130\n","batch_size : 32, number of batch : 18\n","on user number 131\n","batch_size : 32, number of batch : 22\n","on user number 132\n","batch_size : 32, number of batch : 5\n","on user number 133\n","batch_size : 32, number of batch : 22\n","on user number 134\n","batch_size : 32, number of batch : 22\n","on user number 135\n","batch_size : 32, number of batch : 22\n","on user number 136\n","batch_size : 32, number of batch : 9\n","on user number 137\n","batch_size : 32, number of batch : 21\n","on user number 138\n","batch_size : 32, number of batch : 4\n","on user number 139\n","batch_size : 32, number of batch : 3\n","on user number 140\n","batch_size : 32, number of batch : 22\n","on user number 141\n","batch_size : 32, number of batch : 22\n","on user number 142\n","batch_size : 32, number of batch : 22\n","on user number 143\n","batch_size : 32, number of batch : 7\n","on user number 144\n","batch_size : 32, number of batch : 21\n","on user number 145\n","batch_size : 32, number of batch : 22\n","on user number 146\n","batch_size : 32, number of batch : 16\n","on user number 147\n","batch_size : 32, number of batch : 22\n","on user number 148\n","batch_size : 32, number of batch : 22\n","on user number 149\n","batch_size : 32, number of batch : 22\n","on user number 150\n","batch_size : 32, number of batch : 8\n","on user number 151\n","batch_size : 32, number of batch : 22\n","on user number 152\n","batch_size : 32, number of batch : 7\n","on user number 153\n","batch_size : 32, number of batch : 19\n","on user number 154\n","batch_size : 32, number of batch : 20\n","on user number 155\n","batch_size : 32, number of batch : 22\n","on user number 156\n","batch_size : 32, number of batch : 22\n","on user number 157\n","batch_size : 32, number of batch : 22\n","on user number 158\n","batch_size : 32, number of batch : 22\n","on user number 159\n","batch_size : 32, number of batch : 22\n","on user number 160\n","batch_size : 32, number of batch : 22\n","on user number 161\n","batch_size : 32, number of batch : 15\n","on user number 162\n","batch_size : 32, number of batch : 22\n","on user number 163\n","batch_size : 32, number of batch : 22\n","on user number 164\n","batch_size : 32, number of batch : 16\n","on user number 165\n","batch_size : 32, number of batch : 22\n","on user number 166\n","batch_size : 32, number of batch : 22\n","on user number 167\n","batch_size : 32, number of batch : 22\n","on user number 168\n","batch_size : 32, number of batch : 22\n","on user number 169\n","batch_size : 32, number of batch : 12\n","on user number 170\n","batch_size : 32, number of batch : 22\n","on user number 171\n","batch_size : 32, number of batch : 22\n","on user number 172\n","batch_size : 32, number of batch : 22\n","on user number 173\n","batch_size : 32, number of batch : 22\n","on user number 174\n","batch_size : 32, number of batch : 19\n","on user number 175\n","batch_size : 32, number of batch : 22\n","on user number 176\n","batch_size : 32, number of batch : 7\n","on user number 177\n","batch_size : 32, number of batch : 22\n","on user number 178\n","batch_size : 32, number of batch : 11\n","on user number 179\n","batch_size : 32, number of batch : 4\n","on user number 180\n","batch_size : 32, number of batch : 22\n","on user number 181\n","batch_size : 32, number of batch : 4\n","on user number 182\n","batch_size : 32, number of batch : 22\n","on user number 183\n","batch_size : 32, number of batch : 22\n","on user number 184\n","batch_size : 32, number of batch : 8\n","on user number 185\n","batch_size : 32, number of batch : 22\n","on user number 186\n","batch_size : 32, number of batch : 6\n","on user number 187\n","batch_size : 32, number of batch : 22\n","on user number 188\n","batch_size : 32, number of batch : 22\n","on user number 189\n","batch_size : 32, number of batch : 22\n","on user number 190\n","batch_size : 32, number of batch : 9\n","on user number 191\n","batch_size : 32, number of batch : 3\n","on user number 192\n","batch_size : 32, number of batch : 3\n","on user number 193\n","batch_size : 32, number of batch : 22\n","on user number 194\n","batch_size : 32, number of batch : 22\n","on user number 195\n","batch_size : 32, number of batch : 22\n","on user number 196\n","batch_size : 32, number of batch : 22\n","on user number 197\n","batch_size : 32, number of batch : 22\n","on user number 198\n","batch_size : 32, number of batch : 22\n","on user number 199\n","batch_size : 32, number of batch : 22\n","on user number 200\n","batch_size : 32, number of batch : 22\n","on user number 201\n","batch_size : 32, number of batch : 22\n","on user number 202\n","batch_size : 32, number of batch : 22\n","on user number 203\n","batch_size : 32, number of batch : 8\n","on user number 204\n","batch_size : 32, number of batch : 22\n","on user number 205\n","batch_size : 32, number of batch : 22\n","on user number 206\n","batch_size : 32, number of batch : 22\n","on user number 207\n","batch_size : 32, number of batch : 22\n","on user number 208\n","batch_size : 32, number of batch : 17\n","on user number 209\n","batch_size : 32, number of batch : 22\n","on user number 210\n","batch_size : 32, number of batch : 2\n","on user number 211\n","batch_size : 32, number of batch : 21\n","on user number 212\n","batch_size : 32, number of batch : 22\n","on user number 213\n","batch_size : 32, number of batch : 22\n","on user number 214\n","batch_size : 32, number of batch : 22\n","on user number 215\n","batch_size : 32, number of batch : 22\n","on user number 216\n","batch_size : 32, number of batch : 22\n","on user number 217\n","batch_size : 32, number of batch : 22\n","on user number 218\n","batch_size : 32, number of batch : 16\n","on user number 219\n","batch_size : 32, number of batch : 22\n","on user number 220\n","batch_size : 32, number of batch : 22\n","on user number 221\n","batch_size : 32, number of batch : 7\n","on user number 222\n","batch_size : 32, number of batch : 22\n","on user number 223\n","batch_size : 32, number of batch : 22\n","on user number 224\n","batch_size : 32, number of batch : 5\n","on user number 225\n","batch_size : 32, number of batch : 22\n","on user number 226\n","batch_size : 32, number of batch : 22\n","on user number 227\n","batch_size : 32, number of batch : 22\n","on user number 228\n","batch_size : 32, number of batch : 22\n","on user number 229\n","batch_size : 32, number of batch : 6\n","on user number 230\n","batch_size : 32, number of batch : 17\n","on user number 231\n","batch_size : 32, number of batch : 5\n","on user number 232\n","batch_size : 32, number of batch : 22\n","on user number 233\n","batch_size : 32, number of batch : 10\n","on user number 234\n","batch_size : 32, number of batch : 22\n","on user number 235\n","batch_size : 32, number of batch : 22\n","on user number 236\n","batch_size : 32, number of batch : 22\n","on user number 237\n","batch_size : 32, number of batch : 22\n","on user number 238\n","batch_size : 32, number of batch : 22\n","on user number 239\n","batch_size : 32, number of batch : 22\n","on user number 240\n","Epoch 2/2 - Loss: 169.84832301735878\n"]}],"source":["from tqdm import tqdm\n","import random\n","\n","epochs_loss = {\"train\": [], \"val\": [], \"test\": []}\n","epochs_acc = {\"train\": [], \"val\": [], \"test\": []}\n","\n","\n","model.train()\n","\n","# Train the model\n","for epoch in range(NUM_EPOCHS):\n","    running_loss = 0.0\n","    indices = list(range(len(X_train)))\n","    random.shuffle(indices)\n","    counter = 0\n","\n","    for index in indices:\n","        model_inputs = tokenizer(X_train[index], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","        logits = model(input_ids=model_inputs.input_ids, attention_mask=model_inputs.attention_mask)\n","        label = torch.tensor([y_train[index]]).to(device)\n","\n","        # Compute loss\n","        loss = loss_fn(logits, label)\n","\n","        # Backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        counter += 1\n","        # Log the loss\n","        running_loss += loss.item()\n","        # print(f\"{counter} ->\", end=\" \")\n","        print(f\"on user number {counter}\")\n","\n","    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Loss: {running_loss}\")\n","    # del model_inputs\n","    # del loss\n","    # del logits\n","    # gc.collect()\n","    # torch.cuda.empty_cache()\n","\n","\n","\n","\n","    # # Log the average loss for the epoch\n","    # print(f'loss {running_loss}')\n","    # # running_loss = 0\n","    # torch.cuda.empty_cache()\n","    # gc.collect()\n","\n"," # now we are making each user as a separate user and then getting mean on each splitted user\n","\n"]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP/bert_in_bert/model_1.pth\")"],"metadata":{"id":"EXNdnadAx9i0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def model_validation(X, y, model):\n","    loss = []\n","    prediction_is_correct = []\n","    with torch.no_grad():\n","        for i, tweets in enumerate(X):\n","            print(f\"user {i}:\")\n","            model_inputs = tokenizer(tweets, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","            logits = model(input_ids=model_inputs.input_ids, attention_mask=model_inputs.attention_mask)\n","            label = torch.tensor([y[i]]).to(device)\n","            user_loss = loss_fn(logits, label)\n","            loss.append(user_loss.item())\n","            train_predicted_label = 0 if logits[0].item() < 0.32 else 0\n","            print(f\"predicated label is : {logits}\")\n","            if train_predicted_label == y[i]:\n","                prediction_is_correct.append(1)\n","            else:\n","                prediction_is_correct.append(0)\n","    print(f\"average loss is : {sum(loss) / len(loss)}\\naccuracy is : {sum(prediction_is_correct) / len(prediction_is_correct)}\")\n","    return sum(loss) / len(loss), sum(prediction_is_correct) / len(prediction_is_correct)"],"metadata":{"id":"20Hc-GYHkDPk","executionInfo":{"status":"ok","timestamp":1688980042444,"user_tz":-210,"elapsed":26,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP/bert_in_bert/model.pth\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0mxUmi1b9FA","executionInfo":{"status":"ok","timestamp":1688938341443,"user_tz":-210,"elapsed":7763,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}},"outputId":"f75e5db8-8e85-4de0-b02e-db7a13b1bbf4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["X_train_tmp, y_train_tmp = X_train[:50], y_train[:50]\n","X_test_tmp, y_test_tmp = X_test[:50], y_test[:50]\n","X_val_tmp, y_val_tmp = X_val[:50], y_val[:50]"],"metadata":{"id":"B6MOZdRtgZFj","executionInfo":{"status":"ok","timestamp":1688980042445,"user_tz":-210,"elapsed":16,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["1 == y_train_tmp[0]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2xNmj9poOfK","executionInfo":{"status":"ok","timestamp":1688939346475,"user_tz":-210,"elapsed":2,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}},"outputId":"59a759ba-c90f-4878-8b72-cc441ecc0699"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["loss_train, acc_train = model_validation(X_train_tmp, y_train_tmp, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THEGfFKWgZbc","executionInfo":{"status":"ok","timestamp":1688980163797,"user_tz":-210,"elapsed":121367,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}},"outputId":"6a9e2413-9fd3-44af-849c-7d9e8e28a80c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["user 0:\n","batch_size : 32, number of batch : 17\n","predicated label is : tensor([0.4908], device='cuda:0')\n","user 1:\n","batch_size : 32, number of batch : 17\n","predicated label is : tensor([0.5000], device='cuda:0')\n","user 2:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4628], device='cuda:0')\n","user 3:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4494], device='cuda:0')\n","user 4:\n","batch_size : 32, number of batch : 21\n","predicated label is : tensor([0.4114], device='cuda:0')\n","user 5:\n","batch_size : 32, number of batch : 17\n","predicated label is : tensor([0.4033], device='cuda:0')\n","user 6:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3840], device='cuda:0')\n","user 7:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4363], device='cuda:0')\n","user 8:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4928], device='cuda:0')\n","user 9:\n","batch_size : 32, number of batch : 20\n","predicated label is : tensor([0.4593], device='cuda:0')\n","user 10:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5197], device='cuda:0')\n","user 11:\n","batch_size : 32, number of batch : 19\n","predicated label is : tensor([0.3921], device='cuda:0')\n","user 12:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4223], device='cuda:0')\n","user 13:\n","batch_size : 32, number of batch : 21\n","predicated label is : tensor([0.4287], device='cuda:0')\n","user 14:\n","batch_size : 32, number of batch : 2\n","predicated label is : tensor([0.3877], device='cuda:0')\n","user 15:\n","batch_size : 32, number of batch : 15\n","predicated label is : tensor([0.4667], device='cuda:0')\n","user 16:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4261], device='cuda:0')\n","user 17:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5128], device='cuda:0')\n","user 18:\n","batch_size : 32, number of batch : 6\n","predicated label is : tensor([0.3972], device='cuda:0')\n","user 19:\n","batch_size : 32, number of batch : 5\n","predicated label is : tensor([0.4364], device='cuda:0')\n","user 20:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3863], device='cuda:0')\n","user 21:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3738], device='cuda:0')\n","user 22:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5260], device='cuda:0')\n","user 23:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3891], device='cuda:0')\n","user 24:\n","batch_size : 32, number of batch : 7\n","predicated label is : tensor([0.4429], device='cuda:0')\n","user 25:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4807], device='cuda:0')\n","user 26:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4669], device='cuda:0')\n","user 27:\n","batch_size : 32, number of batch : 6\n","predicated label is : tensor([0.3589], device='cuda:0')\n","user 28:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4523], device='cuda:0')\n","user 29:\n","batch_size : 32, number of batch : 6\n","predicated label is : tensor([0.4551], device='cuda:0')\n","user 30:\n","batch_size : 32, number of batch : 15\n","predicated label is : tensor([0.3543], device='cuda:0')\n","user 31:\n","batch_size : 32, number of batch : 14\n","predicated label is : tensor([0.5183], device='cuda:0')\n","user 32:\n","batch_size : 32, number of batch : 5\n","predicated label is : tensor([0.4499], device='cuda:0')\n","user 33:\n","batch_size : 32, number of batch : 15\n","predicated label is : tensor([0.4840], device='cuda:0')\n","user 34:\n","batch_size : 32, number of batch : 5\n","predicated label is : tensor([0.4275], device='cuda:0')\n","user 35:\n","batch_size : 32, number of batch : 3\n","predicated label is : tensor([0.3575], device='cuda:0')\n","user 36:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4626], device='cuda:0')\n","user 37:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4258], device='cuda:0')\n","user 38:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4183], device='cuda:0')\n","user 39:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4231], device='cuda:0')\n","user 40:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4741], device='cuda:0')\n","user 41:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4182], device='cuda:0')\n","user 42:\n","batch_size : 32, number of batch : 10\n","predicated label is : tensor([0.3958], device='cuda:0')\n","user 43:\n","batch_size : 32, number of batch : 17\n","predicated label is : tensor([0.4622], device='cuda:0')\n","user 44:\n","batch_size : 32, number of batch : 21\n","predicated label is : tensor([0.4471], device='cuda:0')\n","user 45:\n","batch_size : 32, number of batch : 18\n","predicated label is : tensor([0.3656], device='cuda:0')\n","user 46:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4105], device='cuda:0')\n","user 47:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4402], device='cuda:0')\n","user 48:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3545], device='cuda:0')\n","user 49:\n","batch_size : 32, number of batch : 4\n","predicated label is : tensor([0.4506], device='cuda:0')\n","average loss is : 0.6871001213788986\n","accuracy is : 0.54\n"]}]},{"cell_type":"code","source":["loss_test, acc_test = model_validation(X_test_tmp, y_test_tmp, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qBvMgjm9iIPF","executionInfo":{"status":"ok","timestamp":1688980303719,"user_tz":-210,"elapsed":139923,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}},"outputId":"4e464554-37ad-4085-8d86-19067aa57297"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["user 0:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3914], device='cuda:0')\n","user 1:\n","batch_size : 32, number of batch : 9\n","predicated label is : tensor([0.4995], device='cuda:0')\n","user 2:\n","batch_size : 32, number of batch : 12\n","predicated label is : tensor([0.3772], device='cuda:0')\n","user 3:\n","batch_size : 32, number of batch : 17\n","predicated label is : tensor([0.4095], device='cuda:0')\n","user 4:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4342], device='cuda:0')\n","user 5:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3991], device='cuda:0')\n","user 6:\n","batch_size : 32, number of batch : 20\n","predicated label is : tensor([0.4221], device='cuda:0')\n","user 7:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4182], device='cuda:0')\n","user 8:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4249], device='cuda:0')\n","user 9:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4082], device='cuda:0')\n","user 10:\n","batch_size : 32, number of batch : 21\n","predicated label is : tensor([0.4958], device='cuda:0')\n","user 11:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4068], device='cuda:0')\n","user 12:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4424], device='cuda:0')\n","user 13:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3666], device='cuda:0')\n","user 14:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5444], device='cuda:0')\n","user 15:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4631], device='cuda:0')\n","user 16:\n","batch_size : 32, number of batch : 9\n","predicated label is : tensor([0.4592], device='cuda:0')\n","user 17:\n","batch_size : 32, number of batch : 8\n","predicated label is : tensor([0.3017], device='cuda:0')\n","user 18:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3782], device='cuda:0')\n","user 19:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4441], device='cuda:0')\n","user 20:\n","batch_size : 32, number of batch : 18\n","predicated label is : tensor([0.3738], device='cuda:0')\n","user 21:\n","batch_size : 32, number of batch : 9\n","predicated label is : tensor([0.4220], device='cuda:0')\n","user 22:\n","batch_size : 32, number of batch : 19\n","predicated label is : tensor([0.4822], device='cuda:0')\n","user 23:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4246], device='cuda:0')\n","user 24:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4765], device='cuda:0')\n","user 25:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3999], device='cuda:0')\n","user 26:\n","batch_size : 32, number of batch : 8\n","predicated label is : tensor([0.5055], device='cuda:0')\n","user 27:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3487], device='cuda:0')\n","user 28:\n","batch_size : 32, number of batch : 10\n","predicated label is : tensor([0.4727], device='cuda:0')\n","user 29:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4188], device='cuda:0')\n","user 30:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4264], device='cuda:0')\n","user 31:\n","batch_size : 32, number of batch : 19\n","predicated label is : tensor([0.5098], device='cuda:0')\n","user 32:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5417], device='cuda:0')\n","user 33:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4133], device='cuda:0')\n","user 34:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5286], device='cuda:0')\n","user 35:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4543], device='cuda:0')\n","user 36:\n","batch_size : 32, number of batch : 5\n","predicated label is : tensor([0.3905], device='cuda:0')\n","user 37:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4158], device='cuda:0')\n","user 38:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4410], device='cuda:0')\n","user 39:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4164], device='cuda:0')\n","user 40:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3878], device='cuda:0')\n","user 41:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4228], device='cuda:0')\n","user 42:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4021], device='cuda:0')\n","user 43:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4524], device='cuda:0')\n","user 44:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4595], device='cuda:0')\n","user 45:\n","batch_size : 32, number of batch : 12\n","predicated label is : tensor([0.3680], device='cuda:0')\n","user 46:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3983], device='cuda:0')\n","user 47:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4115], device='cuda:0')\n","user 48:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5028], device='cuda:0')\n","user 49:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3720], device='cuda:0')\n","average loss is : 0.6370650708675385\n","accuracy is : 0.72\n"]}]},{"cell_type":"code","source":["loss_val, acc_val = model_validation(X_val_tmp, y_val_tmp, model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnc3MN18ipWx","executionInfo":{"status":"ok","timestamp":1688980426675,"user_tz":-210,"elapsed":122963,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}},"outputId":"4b35e276-3fc0-44a5-ee06-1a43d6355061"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["user 0:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4151], device='cuda:0')\n","user 1:\n","batch_size : 32, number of batch : 15\n","predicated label is : tensor([0.4263], device='cuda:0')\n","user 2:\n","batch_size : 32, number of batch : 12\n","predicated label is : tensor([0.4665], device='cuda:0')\n","user 3:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3806], device='cuda:0')\n","user 4:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5132], device='cuda:0')\n","user 5:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4365], device='cuda:0')\n","user 6:\n","batch_size : 32, number of batch : 6\n","predicated label is : tensor([0.4248], device='cuda:0')\n","user 7:\n","batch_size : 32, number of batch : 4\n","predicated label is : tensor([0.3437], device='cuda:0')\n","user 8:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3953], device='cuda:0')\n","user 9:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4537], device='cuda:0')\n","user 10:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5029], device='cuda:0')\n","user 11:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3878], device='cuda:0')\n","user 12:\n","batch_size : 32, number of batch : 17\n","predicated label is : tensor([0.4001], device='cuda:0')\n","user 13:\n","batch_size : 32, number of batch : 6\n","predicated label is : tensor([0.3704], device='cuda:0')\n","user 14:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4989], device='cuda:0')\n","user 15:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4207], device='cuda:0')\n","user 16:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4555], device='cuda:0')\n","user 17:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3822], device='cuda:0')\n","user 18:\n","batch_size : 32, number of batch : 7\n","predicated label is : tensor([0.4310], device='cuda:0')\n","user 19:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4921], device='cuda:0')\n","user 20:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3800], device='cuda:0')\n","user 21:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5240], device='cuda:0')\n","user 22:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3643], device='cuda:0')\n","user 23:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4000], device='cuda:0')\n","user 24:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4419], device='cuda:0')\n","user 25:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.2993], device='cuda:0')\n","user 26:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4712], device='cuda:0')\n","user 27:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4372], device='cuda:0')\n","user 28:\n","batch_size : 32, number of batch : 5\n","predicated label is : tensor([0.3783], device='cuda:0')\n","user 29:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3562], device='cuda:0')\n","user 30:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.3643], device='cuda:0')\n","user 31:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4032], device='cuda:0')\n","user 32:\n","batch_size : 32, number of batch : 5\n","predicated label is : tensor([0.2772], device='cuda:0')\n","user 33:\n","batch_size : 32, number of batch : 19\n","predicated label is : tensor([0.4119], device='cuda:0')\n","user 34:\n","batch_size : 32, number of batch : 6\n","predicated label is : tensor([0.4237], device='cuda:0')\n","user 35:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4538], device='cuda:0')\n","user 36:\n","batch_size : 32, number of batch : 19\n","predicated label is : tensor([0.3646], device='cuda:0')\n","user 37:\n","batch_size : 32, number of batch : 4\n","predicated label is : tensor([0.4541], device='cuda:0')\n","user 38:\n","batch_size : 32, number of batch : 4\n","predicated label is : tensor([0.4417], device='cuda:0')\n","user 39:\n","batch_size : 32, number of batch : 14\n","predicated label is : tensor([0.4162], device='cuda:0')\n","user 40:\n","batch_size : 32, number of batch : 10\n","predicated label is : tensor([0.3291], device='cuda:0')\n","user 41:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.5082], device='cuda:0')\n","user 42:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4197], device='cuda:0')\n","user 43:\n","batch_size : 32, number of batch : 7\n","predicated label is : tensor([0.4475], device='cuda:0')\n","user 44:\n","batch_size : 32, number of batch : 4\n","predicated label is : tensor([0.3959], device='cuda:0')\n","user 45:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4106], device='cuda:0')\n","user 46:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4266], device='cuda:0')\n","user 47:\n","batch_size : 32, number of batch : 18\n","predicated label is : tensor([0.4169], device='cuda:0')\n","user 48:\n","batch_size : 32, number of batch : 16\n","predicated label is : tensor([0.4624], device='cuda:0')\n","user 49:\n","batch_size : 32, number of batch : 22\n","predicated label is : tensor([0.4474], device='cuda:0')\n","average loss is : 0.6870729863643646\n","accuracy is : 0.54\n"]}]},{"cell_type":"code","source":["results = pd.DataFrame({\"train\" : [loss_train, acc_train], \"val\": [loss_val, acc_val], \"test\" : [loss_test, acc_test]})\n","results = results.T\n","results.columns = [\"loss\", \"acc\"]"],"metadata":{"id":"QCOoAy5Oit-1","executionInfo":{"status":"ok","timestamp":1688980426676,"user_tz":-210,"elapsed":16,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["results.to_csv(\"/content/drive/MyDrive/NLP/outputs_bert_into_bert_2.csv\")"],"metadata":{"id":"fKGPt-Wunj5P","executionInfo":{"status":"ok","timestamp":1688980426676,"user_tz":-210,"elapsed":15,"user":{"displayName":"mjavad mt","userId":"11804581427658681871"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DLNWQ5Lko1I-"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1iDJH1LSgJQWlpdIU0WB7gH4z70G5WXFj","authorship_tag":"ABX9TyPfClQmb1jAdqMEdEIwcHLl"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1c048ef3a65046da80a1655ed32272b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a0c35b338584fd19869a930cbb1a486","IPY_MODEL_51da5f88adc241cf9f12ccc2bb51c707","IPY_MODEL_254571bb21114c02895796b2826d2a22"],"layout":"IPY_MODEL_672880a844814377a0b83b42d56399be"}},"1a0c35b338584fd19869a930cbb1a486":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f082a7979a81445586fb4625016f3a41","placeholder":"​","style":"IPY_MODEL_97f7b247001a45f1bcff6e2908f24c35","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"51da5f88adc241cf9f12ccc2bb51c707":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07a6bfff6af3412a8d6fe1d8dfdf672a","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a52bc93878f4b0db0cd85bcbe5750ed","value":231508}},"254571bb21114c02895796b2826d2a22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bda621ba3fd4b679c17e3bde18b1f60","placeholder":"​","style":"IPY_MODEL_93466cf4177842d3b3bca187ed78dce5","value":" 232k/232k [00:00&lt;00:00, 4.07MB/s]"}},"672880a844814377a0b83b42d56399be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f082a7979a81445586fb4625016f3a41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97f7b247001a45f1bcff6e2908f24c35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07a6bfff6af3412a8d6fe1d8dfdf672a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a52bc93878f4b0db0cd85bcbe5750ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1bda621ba3fd4b679c17e3bde18b1f60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93466cf4177842d3b3bca187ed78dce5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc1e3087ab5c492fac7ee57384aa5e46":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d3726eb2c2e406d927b14a99fe44736","IPY_MODEL_10d64ab110a540b38722393fec5b0038","IPY_MODEL_acf763932834429986df933ba335e8bb"],"layout":"IPY_MODEL_23aeb84935f24810a934c48eae79fb5e"}},"2d3726eb2c2e406d927b14a99fe44736":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_299b8c98b11249b3890291609183c89c","placeholder":"​","style":"IPY_MODEL_0e87be67fc7648f2ba68d4a249778338","value":"Downloading (…)okenizer_config.json: 100%"}},"10d64ab110a540b38722393fec5b0038":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffdbd4202f1246c19ef73cc4fa224b92","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d52cb7d9962f4d4b92024298eafd8691","value":28}},"acf763932834429986df933ba335e8bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4fe337cb748427d97587993b3c38b87","placeholder":"​","style":"IPY_MODEL_de2cccba15924568bcd4c05bde291645","value":" 28.0/28.0 [00:00&lt;00:00, 1.13kB/s]"}},"23aeb84935f24810a934c48eae79fb5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"299b8c98b11249b3890291609183c89c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e87be67fc7648f2ba68d4a249778338":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffdbd4202f1246c19ef73cc4fa224b92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d52cb7d9962f4d4b92024298eafd8691":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4fe337cb748427d97587993b3c38b87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de2cccba15924568bcd4c05bde291645":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8037a83af49e43869ae98096eb819c49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d4bf2930d56458ba54b40955fed2e62","IPY_MODEL_beb1efca3faf4d19a8173837d0e71544","IPY_MODEL_662d1f32106a44fe88d718c3e14e353e"],"layout":"IPY_MODEL_30c3e55d04aa4dc99083578b8e767f1b"}},"2d4bf2930d56458ba54b40955fed2e62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ae2103dce6f41b19c6442e77f79115b","placeholder":"​","style":"IPY_MODEL_c5dad91c35e84186be79478547d278b5","value":"Downloading (…)lve/main/config.json: 100%"}},"beb1efca3faf4d19a8173837d0e71544":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48af9e35816b475c9558f6aabebd35e4","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e177f8f97574b7d949fa012d0d2c46a","value":570}},"662d1f32106a44fe88d718c3e14e353e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8327d9b8ba340969256e4903b187bcd","placeholder":"​","style":"IPY_MODEL_071910cadc0c4c89ba2f14d59b06a50d","value":" 570/570 [00:00&lt;00:00, 24.5kB/s]"}},"30c3e55d04aa4dc99083578b8e767f1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ae2103dce6f41b19c6442e77f79115b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5dad91c35e84186be79478547d278b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48af9e35816b475c9558f6aabebd35e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e177f8f97574b7d949fa012d0d2c46a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8327d9b8ba340969256e4903b187bcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"071910cadc0c4c89ba2f14d59b06a50d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"846b35e2d357446dba79486b4fa07108":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2d5bea0112340f195e7edb2ad0268ab","IPY_MODEL_ed83558342334ef593bf023849719488","IPY_MODEL_d1bce8be9e3a40a0a000e1fa9642da63"],"layout":"IPY_MODEL_920ead3f8fbe42a7804e00358335ace0"}},"a2d5bea0112340f195e7edb2ad0268ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec6d4aef11754d7482454fbb2370751f","placeholder":"​","style":"IPY_MODEL_e12b51ee26bf437a809543b370228a99","value":"Downloading pytorch_model.bin: 100%"}},"ed83558342334ef593bf023849719488":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_764b1c1fed5e476fa1a3f8204b545b34","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e042b24933c4708a5beecbbf7ef04a3","value":440473133}},"d1bce8be9e3a40a0a000e1fa9642da63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5043212c2d445ad8e5cc00c410694ce","placeholder":"​","style":"IPY_MODEL_09fe98ad83ae4811a7725699457e9d30","value":" 440M/440M [00:02&lt;00:00, 204MB/s]"}},"920ead3f8fbe42a7804e00358335ace0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec6d4aef11754d7482454fbb2370751f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e12b51ee26bf437a809543b370228a99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"764b1c1fed5e476fa1a3f8204b545b34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e042b24933c4708a5beecbbf7ef04a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5043212c2d445ad8e5cc00c410694ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09fe98ad83ae4811a7725699457e9d30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3accb3cd0e194ab3964d8e8e636aefdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3245a40df6554f2990204beadb1aeed6","IPY_MODEL_50c383cb01fb479684db96664fffc8d0","IPY_MODEL_4ae690ee871c4e9f8ed6ab21cd4337bd"],"layout":"IPY_MODEL_61e701f5504a4795af573f4cf30fbacf"}},"3245a40df6554f2990204beadb1aeed6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29bc3717845d4a60b5c555020fa95b44","placeholder":"​","style":"IPY_MODEL_0497a4e9d6f84b59b3ec02c77776f0dd","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"50c383cb01fb479684db96664fffc8d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec003144413c4edc940c8a9f441575e5","max":1198122,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a71746f9a0040bcb9e4fe1f5b68ea8e","value":1198122}},"4ae690ee871c4e9f8ed6ab21cd4337bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_670f65a204dc4d8aab54d870a86c5252","placeholder":"​","style":"IPY_MODEL_41f5f1dc5ea941e6b8e788af94cfa10e","value":" 1.20M/1.20M [00:00&lt;00:00, 11.9MB/s]"}},"61e701f5504a4795af573f4cf30fbacf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29bc3717845d4a60b5c555020fa95b44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0497a4e9d6f84b59b3ec02c77776f0dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec003144413c4edc940c8a9f441575e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a71746f9a0040bcb9e4fe1f5b68ea8e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"670f65a204dc4d8aab54d870a86c5252":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41f5f1dc5ea941e6b8e788af94cfa10e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32dbe4191f3f4f7e8b8607b38f1c0eb9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d64a0600b50494e8e4e6f32f8bcb994","IPY_MODEL_befea868a39d43ca95a20880e661f030","IPY_MODEL_ff2775a5270b435a8af558a27fafe083"],"layout":"IPY_MODEL_48427f4248334ca1856d97bfb718b912"}},"9d64a0600b50494e8e4e6f32f8bcb994":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e72d5c408be44ab3b2ce04e604ee35d5","placeholder":"​","style":"IPY_MODEL_531f3676ec7a42848998ea0156c6dffc","value":"Downloading (…)lve/main/config.json: 100%"}},"befea868a39d43ca95a20880e661f030":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29a8c5d1902944e99bda8e4b6f251ae5","max":440,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4827b397a214b4ab70afb77c2e98aa8","value":440}},"ff2775a5270b435a8af558a27fafe083":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb9a147d0d73458db14ede2f9693947a","placeholder":"​","style":"IPY_MODEL_0cf3db4fdadf4d498ea453577215eafa","value":" 440/440 [00:00&lt;00:00, 20.1kB/s]"}},"48427f4248334ca1856d97bfb718b912":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e72d5c408be44ab3b2ce04e604ee35d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"531f3676ec7a42848998ea0156c6dffc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29a8c5d1902944e99bda8e4b6f251ae5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4827b397a214b4ab70afb77c2e98aa8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fb9a147d0d73458db14ede2f9693947a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cf3db4fdadf4d498ea453577215eafa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37512743933c488e820b02a8a8c9d746":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54990aba7e41459bbb2f2d4383f9a794","IPY_MODEL_1b93cdcef2824a2ab03d9f640b339de0","IPY_MODEL_86ebc3942dc8403d966dc02f5fd47914"],"layout":"IPY_MODEL_24dfd707e49444468f191cdde5d7b8c0"}},"54990aba7e41459bbb2f2d4383f9a794":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df0f501fc31a426ab356fe06c11b67bd","placeholder":"​","style":"IPY_MODEL_9f30803ec2994e98881b3c1ffdedb663","value":"Downloading pytorch_model.bin: 100%"}},"1b93cdcef2824a2ab03d9f640b339de0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_276b5392fdee4085b6c9edcfbdff9243","max":654226731,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0f7c640074a468e9c1a37172abed3e0","value":654226731}},"86ebc3942dc8403d966dc02f5fd47914":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8edcb5ce34844933968b6b67b1481d57","placeholder":"​","style":"IPY_MODEL_918dbb0d2d9b47f49dbadf2af07a5589","value":" 654M/654M [00:04&lt;00:00, 191MB/s]"}},"24dfd707e49444468f191cdde5d7b8c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df0f501fc31a426ab356fe06c11b67bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f30803ec2994e98881b3c1ffdedb663":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"276b5392fdee4085b6c9edcfbdff9243":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0f7c640074a468e9c1a37172abed3e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8edcb5ce34844933968b6b67b1481d57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"918dbb0d2d9b47f49dbadf2af07a5589":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}